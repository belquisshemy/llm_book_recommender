import pandas as pd 
import numpy as np
from dotenv import load_dotenv
import os


from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import CharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma

import gradio as gr

load_dotenv()
books = pd.read_csv("books_with_emotions.csv")

books["large_thumbnail"] = np.where(
    books["thumbnail"].isna(),
    "cover-not-found.jpg",
    books["thumbnail"] + "&fife=w800"
)
# --- ChromaDB Setup with Persistence ---
PERSIST_DIRECTORY = "./chroma_db_books" # Define a directory to store the DB files

if not os.path.exists(PERSIST_DIRECTORY):
    # If the database directory does not exist, create and populate it
    print(f"Creating new ChromaDB at {PERSIST_DIRECTORY}...")
    raw_documents = TextLoader("tagged_description.txt").load()
    text_splitter = CharacterTextSplitter(separator="\n", chunk_size=0, chunk_overlap=0)
    documents = text_splitter.split_documents(raw_documents)
    
    # Initialize embeddings (this will make API calls if it's the first time)
    embeddings_model = OpenAIEmbeddings() 
    
    # Create the DB from documents and persist it
    db_books = Chroma.from_documents(documents, embeddings_model, persist_directory=PERSIST_DIRECTORY)
    # db_books.persist() # As of recent LangChain/Chroma versions, from_documents often persists automatically if directory is given.
                        # Explicit .persist() might be needed in older versions or specific setups.
else:
    # If the database directory already exists, load it
    print(f"Loading existing ChromaDB from {PERSIST_DIRECTORY}...")
    embeddings_model = OpenAIEmbeddings() # Need to pass the same embedding function used to create it
    db_books = Chroma(persist_directory=PERSIST_DIRECTORY, embedding_function=embeddings_model)


"""
1- retrieve_semantic_recommendations Function:
Vector search performed on the vector representation "embedding" generated by the OpenAIEmbedding model
"""

def retrieve_semantic_recommendations(
        query: str,
        category: str = "All", # Set default to "All" directly
        tone: str = "All",     # Set default to "All" directly
        initial_top_k: int = 50,
        final_top_k: int = 16,
) -> pd.DataFrame:

    recs = db_books.similarity_search(query, k=initial_top_k)
    #maxsplit=1 ensures only the first split happens.
    book_isbns = [int(rec.page_content.strip('"').split(maxsplit=1)[0]) for rec in recs]
    
    # Filter the main books DataFrame once
    book_recs = books[books["isbn13"].isin(book_isbns)].copy() # Use .copy() to avoid SettingWithCopyWarning

    # Apply category filter
    if category != "All":
        book_recs = book_recs[book_recs["simple_categories"] == category]

    # Apply tone sorting using a dictionary lookup for readability
    tone_sort_map = {
        "Happy": "joy",
        "Surprising": "surprise",
        "Angry": "anger",
        "Suspenseful": "fear",
        "Sad": "sadness"
    }
    
    sort_column = tone_sort_map.get(tone)
    if sort_column: # If a valid tone was selected
        book_recs = book_recs.sort_values(by=sort_column, ascending=False)
    
    # Finally, truncate to final_top_k after all filtering and sorting
    return book_recs.head(final_top_k)

"""
2- recommend_books: returns recommended book by image + title + authors name + truncuated description
"""

def recommend_books(
        query: str,
        category: str,
        tone: str
):
    recommendations = retrieve_semantic_recommendations(query, category, tone)
    
    # Using a list comprehension for a more concise loop
    results = [
        (
            row["large_thumbnail"],
            format_book_caption(row) # Delegate caption formatting to a helper function
        )
        for _, row in recommendations.iterrows()
    ]
    return results

# Helper function for cleaner caption formatting
def format_book_caption(row: pd.Series) -> str:
    # Truncate description
    description_words = row["description"].split()
    truncated_description = " ".join(description_words[:30]) + "..."

    # Format authors
    authors_split = row["authors"].split(";")
    if len(authors_split) == 2:
        authors_str = f"{authors_split[0]} and {authors_split[1]}"
    elif len(authors_split) > 2:
        authors_str = f"{', '.join(authors_split[:-1])}, and {authors_split[-1]}"
    else:
        authors_str = row["authors"] # Handles single author or empty string

    return f"{row['title']} by {authors_str}: {truncated_description}"

"""
3- Gradio Interface
"""

categories = ["All"] + sorted(books["simple_categories"].unique())
tones = ["All"] + ["Happy", "Surprising", "Angry", "Suspenseful", "Sad"]

with gr.Blocks(theme = gr.themes.Glass()) as dashboard:
    gr.Markdown("# Semantic book recommender")

    with gr.Row():
        user_query = gr.Textbox(label = "Please enter a description of a book:",
                                 placeholder = "e.g., A story about forgiveness")
        category_dropdown = gr.Dropdown(choices = categories, label = "Select a category:", value = "All")
        tone_dropdown = gr.Dropdown(choices = tones, label = "Select an emotional tone:", value = "All")
        submit_button = gr.Button("Find recommendations")

    gr.Markdown("## Recommendations")
    output = gr.Gallery(label = "Recommended books", columns = 8, rows = 2)

    submit_button.click(fn = recommend_books,
                        inputs = [user_query, category_dropdown, tone_dropdown],
                        outputs = output)


if __name__ == "__main__":
    dashboard.launch()